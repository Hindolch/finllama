[
  {
    "loss": 2.9743,
    "grad_norm": 1.0059126615524292,
    "learning_rate": 0.00019906666666666666,
    "epoch": 0.013333333333333334,
    "step": 10
  },
  {
    "loss": 2.6691,
    "grad_norm": 0.645460844039917,
    "learning_rate": 0.00019773333333333336,
    "epoch": 0.02666666666666667,
    "step": 20
  },
  {
    "loss": 2.6424,
    "grad_norm": 0.853041410446167,
    "learning_rate": 0.0001964,
    "epoch": 0.04,
    "step": 30
  },
  {
    "loss": 2.5983,
    "grad_norm": 0.9135887622833252,
    "learning_rate": 0.00019506666666666667,
    "epoch": 0.05333333333333334,
    "step": 40
  },
  {
    "loss": 2.5241,
    "grad_norm": 0.8413026332855225,
    "learning_rate": 0.00019373333333333334,
    "epoch": 0.06666666666666667,
    "step": 50
  },
  {
    "loss": 2.49,
    "grad_norm": 0.6395958065986633,
    "learning_rate": 0.00019240000000000001,
    "epoch": 0.08,
    "step": 60
  },
  {
    "loss": 2.6257,
    "grad_norm": 0.9550157189369202,
    "learning_rate": 0.00019106666666666668,
    "epoch": 0.09333333333333334,
    "step": 70
  },
  {
    "loss": 2.4704,
    "grad_norm": 0.6698903441429138,
    "learning_rate": 0.00018973333333333333,
    "epoch": 0.10666666666666667,
    "step": 80
  },
  {
    "loss": 2.5656,
    "grad_norm": 0.6182695627212524,
    "learning_rate": 0.0001884,
    "epoch": 0.12,
    "step": 90
  },
  {
    "loss": 2.4087,
    "grad_norm": 1.340796947479248,
    "learning_rate": 0.00018706666666666667,
    "epoch": 0.13333333333333333,
    "step": 100
  },
  {
    "loss": 2.4387,
    "grad_norm": 0.7854698896408081,
    "learning_rate": 0.00018573333333333334,
    "epoch": 0.14666666666666667,
    "step": 110
  },
  {
    "loss": 2.4454,
    "grad_norm": 0.6198599338531494,
    "learning_rate": 0.0001844,
    "epoch": 0.16,
    "step": 120
  },
  {
    "loss": 2.3695,
    "grad_norm": 0.4417884647846222,
    "learning_rate": 0.00018306666666666668,
    "epoch": 0.17333333333333334,
    "step": 130
  },
  {
    "loss": 2.547,
    "grad_norm": 0.5218032002449036,
    "learning_rate": 0.00018173333333333332,
    "epoch": 0.18666666666666668,
    "step": 140
  },
  {
    "loss": 2.61,
    "grad_norm": 0.8767865300178528,
    "learning_rate": 0.00018040000000000002,
    "epoch": 0.2,
    "step": 150
  },
  {
    "loss": 2.5074,
    "grad_norm": 0.6534563899040222,
    "learning_rate": 0.00017906666666666666,
    "epoch": 0.21333333333333335,
    "step": 160
  },
  {
    "loss": 2.4638,
    "grad_norm": 0.5944600105285645,
    "learning_rate": 0.00017773333333333336,
    "epoch": 0.22666666666666666,
    "step": 170
  },
  {
    "loss": 2.5152,
    "grad_norm": 0.4539392590522766,
    "learning_rate": 0.0001764,
    "epoch": 0.24,
    "step": 180
  },
  {
    "loss": 2.5226,
    "grad_norm": 1.0444109439849854,
    "learning_rate": 0.00017506666666666668,
    "epoch": 0.25333333333333335,
    "step": 190
  },
  {
    "loss": 2.5214,
    "grad_norm": 0.6478605270385742,
    "learning_rate": 0.00017373333333333335,
    "epoch": 0.26666666666666666,
    "step": 200
  },
  {
    "eval_loss": 2.485874891281128,
    "eval_runtime": 220.0544,
    "eval_samples_per_second": 2.272,
    "eval_steps_per_second": 2.272,
    "epoch": 0.26666666666666666,
    "step": 200
  },
  {
    "loss": 2.4805,
    "grad_norm": 0.6552494764328003,
    "learning_rate": 0.00017240000000000002,
    "epoch": 0.28,
    "step": 210
  },
  {
    "loss": 2.3728,
    "grad_norm": 0.9873943328857422,
    "learning_rate": 0.00017106666666666666,
    "epoch": 0.29333333333333333,
    "step": 220
  },
  {
    "loss": 2.4482,
    "grad_norm": 0.5630915760993958,
    "learning_rate": 0.00016973333333333336,
    "epoch": 0.30666666666666664,
    "step": 230
  },
  {
    "loss": 2.4221,
    "grad_norm": 0.44627895951271057,
    "learning_rate": 0.0001684,
    "epoch": 0.32,
    "step": 240
  },
  {
    "loss": 2.4517,
    "grad_norm": 0.42666247487068176,
    "learning_rate": 0.00016706666666666667,
    "epoch": 0.3333333333333333,
    "step": 250
  },
  {
    "loss": 2.5219,
    "grad_norm": 0.6156532764434814,
    "learning_rate": 0.00016573333333333334,
    "epoch": 0.3466666666666667,
    "step": 260
  },
  {
    "loss": 2.466,
    "grad_norm": 0.5165886878967285,
    "learning_rate": 0.0001644,
    "epoch": 0.36,
    "step": 270
  },
  {
    "loss": 2.4941,
    "grad_norm": 0.6442100405693054,
    "learning_rate": 0.00016306666666666668,
    "epoch": 0.37333333333333335,
    "step": 280
  },
  {
    "loss": 2.4561,
    "grad_norm": 0.6198933124542236,
    "learning_rate": 0.00016173333333333333,
    "epoch": 0.38666666666666666,
    "step": 290
  },
  {
    "loss": 2.4531,
    "grad_norm": 0.595128059387207,
    "learning_rate": 0.00016040000000000002,
    "epoch": 0.4,
    "step": 300
  },
  {
    "loss": 2.412,
    "grad_norm": 0.5725652575492859,
    "learning_rate": 0.00015906666666666667,
    "epoch": 0.41333333333333333,
    "step": 310
  },
  {
    "loss": 2.3918,
    "grad_norm": 0.4942736029624939,
    "learning_rate": 0.00015773333333333334,
    "epoch": 0.4266666666666667,
    "step": 320
  },
  {
    "loss": 2.356,
    "grad_norm": 0.6145442724227905,
    "learning_rate": 0.0001564,
    "epoch": 0.44,
    "step": 330
  },
  {
    "loss": 2.4401,
    "grad_norm": 0.7523061633110046,
    "learning_rate": 0.00015506666666666668,
    "epoch": 0.4533333333333333,
    "step": 340
  },
  {
    "loss": 2.4615,
    "grad_norm": 0.4783216416835785,
    "learning_rate": 0.00015373333333333335,
    "epoch": 0.4666666666666667,
    "step": 350
  },
  {
    "loss": 2.4405,
    "grad_norm": 0.4924372136592865,
    "learning_rate": 0.00015240000000000002,
    "epoch": 0.48,
    "step": 360
  },
  {
    "loss": 2.4918,
    "grad_norm": 0.49674373865127563,
    "learning_rate": 0.00015106666666666666,
    "epoch": 0.49333333333333335,
    "step": 370
  },
  {
    "loss": 2.4668,
    "grad_norm": 0.5635143518447876,
    "learning_rate": 0.00014973333333333336,
    "epoch": 0.5066666666666667,
    "step": 380
  },
  {
    "loss": 2.5439,
    "grad_norm": 0.7441611886024475,
    "learning_rate": 0.0001484,
    "epoch": 0.52,
    "step": 390
  },
  {
    "loss": 2.4527,
    "grad_norm": 0.4897453188896179,
    "learning_rate": 0.00014706666666666667,
    "epoch": 0.5333333333333333,
    "step": 400
  },
  {
    "eval_loss": 2.4121592044830322,
    "eval_runtime": 220.3353,
    "eval_samples_per_second": 2.269,
    "eval_steps_per_second": 2.269,
    "epoch": 0.5333333333333333,
    "step": 400
  },
  {
    "loss": 2.4658,
    "grad_norm": 0.5525620579719543,
    "learning_rate": 0.00014573333333333334,
    "epoch": 0.5466666666666666,
    "step": 410
  },
  {
    "loss": 2.457,
    "grad_norm": 0.6028642654418945,
    "learning_rate": 0.0001444,
    "epoch": 0.56,
    "step": 420
  },
  {
    "loss": 2.4925,
    "grad_norm": 0.4106745421886444,
    "learning_rate": 0.00014306666666666668,
    "epoch": 0.5733333333333334,
    "step": 430
  },
  {
    "loss": 2.4483,
    "grad_norm": 0.6231068968772888,
    "learning_rate": 0.00014173333333333333,
    "epoch": 0.5866666666666667,
    "step": 440
  },
  {
    "loss": 2.5658,
    "grad_norm": 0.6475099921226501,
    "learning_rate": 0.0001404,
    "epoch": 0.6,
    "step": 450
  },
  {
    "loss": 2.4389,
    "grad_norm": 0.43683481216430664,
    "learning_rate": 0.00013906666666666667,
    "epoch": 0.6133333333333333,
    "step": 460
  },
  {
    "loss": 2.3812,
    "grad_norm": 0.53352952003479,
    "learning_rate": 0.00013773333333333334,
    "epoch": 0.6266666666666667,
    "step": 470
  },
  {
    "loss": 2.5379,
    "grad_norm": 0.6267296671867371,
    "learning_rate": 0.0001364,
    "epoch": 0.64,
    "step": 480
  },
  {
    "loss": 2.377,
    "grad_norm": 0.4203176498413086,
    "learning_rate": 0.00013506666666666668,
    "epoch": 0.6533333333333333,
    "step": 490
  },
  {
    "loss": 2.3392,
    "grad_norm": 0.5852442979812622,
    "learning_rate": 0.00013373333333333332,
    "epoch": 0.6666666666666666,
    "step": 500
  },
  {
    "loss": 2.4129,
    "grad_norm": 0.6325768828392029,
    "learning_rate": 0.00013240000000000002,
    "epoch": 0.68,
    "step": 510
  },
  {
    "loss": 2.5047,
    "grad_norm": 0.37493014335632324,
    "learning_rate": 0.00013106666666666666,
    "epoch": 0.6933333333333334,
    "step": 520
  },
  {
    "loss": 2.5486,
    "grad_norm": 0.8534743189811707,
    "learning_rate": 0.00012973333333333333,
    "epoch": 0.7066666666666667,
    "step": 530
  },
  {
    "loss": 2.4845,
    "grad_norm": 0.5372596979141235,
    "learning_rate": 0.0001284,
    "epoch": 0.72,
    "step": 540
  },
  {
    "loss": 2.4229,
    "grad_norm": 0.917601466178894,
    "learning_rate": 0.00012706666666666667,
    "epoch": 0.7333333333333333,
    "step": 550
  },
  {
    "loss": 2.3836,
    "grad_norm": 0.5315706133842468,
    "learning_rate": 0.00012573333333333334,
    "epoch": 0.7466666666666667,
    "step": 560
  },
  {
    "loss": 2.3721,
    "grad_norm": 0.43137332797050476,
    "learning_rate": 0.00012440000000000002,
    "epoch": 0.76,
    "step": 570
  },
  {
    "loss": 2.4867,
    "grad_norm": 0.4908677339553833,
    "learning_rate": 0.00012306666666666666,
    "epoch": 0.7733333333333333,
    "step": 580
  },
  {
    "loss": 2.3879,
    "grad_norm": 0.6424717307090759,
    "learning_rate": 0.00012173333333333334,
    "epoch": 0.7866666666666666,
    "step": 590
  },
  {
    "loss": 2.4947,
    "grad_norm": 0.542263925075531,
    "learning_rate": 0.0001204,
    "epoch": 0.8,
    "step": 600
  },
  {
    "eval_loss": 2.3615736961364746,
    "eval_runtime": 220.547,
    "eval_samples_per_second": 2.267,
    "eval_steps_per_second": 2.267,
    "epoch": 0.8,
    "step": 600
  },
  {
    "loss": 2.5673,
    "grad_norm": 0.6316356658935547,
    "learning_rate": 0.00011906666666666668,
    "epoch": 0.8133333333333334,
    "step": 610
  },
  {
    "loss": 2.4288,
    "grad_norm": 0.47979798913002014,
    "learning_rate": 0.00011773333333333334,
    "epoch": 0.8266666666666667,
    "step": 620
  },
  {
    "loss": 2.4456,
    "grad_norm": 0.7237298488616943,
    "learning_rate": 0.0001164,
    "epoch": 0.84,
    "step": 630
  },
  {
    "loss": 2.4074,
    "grad_norm": 0.5818387866020203,
    "learning_rate": 0.00011506666666666668,
    "epoch": 0.8533333333333334,
    "step": 640
  },
  {
    "loss": 2.4435,
    "grad_norm": 0.5698131322860718,
    "learning_rate": 0.00011373333333333334,
    "epoch": 0.8666666666666667,
    "step": 650
  },
  {
    "loss": 2.4037,
    "grad_norm": 0.536631166934967,
    "learning_rate": 0.00011240000000000002,
    "epoch": 0.88,
    "step": 660
  },
  {
    "loss": 2.4034,
    "grad_norm": 0.5637395977973938,
    "learning_rate": 0.00011106666666666668,
    "epoch": 0.8933333333333333,
    "step": 670
  },
  {
    "loss": 2.5453,
    "grad_norm": 0.7211658954620361,
    "learning_rate": 0.00010973333333333334,
    "epoch": 0.9066666666666666,
    "step": 680
  },
  {
    "loss": 2.4915,
    "grad_norm": 0.5972124338150024,
    "learning_rate": 0.00010840000000000002,
    "epoch": 0.92,
    "step": 690
  },
  {
    "loss": 2.3503,
    "grad_norm": 0.49489840865135193,
    "learning_rate": 0.00010706666666666668,
    "epoch": 0.9333333333333333,
    "step": 700
  },
  {
    "loss": 2.4567,
    "grad_norm": 0.7803779244422913,
    "learning_rate": 0.00010573333333333333,
    "epoch": 0.9466666666666667,
    "step": 710
  },
  {
    "loss": 2.4931,
    "grad_norm": 0.6419428586959839,
    "learning_rate": 0.0001044,
    "epoch": 0.96,
    "step": 720
  },
  {
    "loss": 2.5185,
    "grad_norm": 0.6292402148246765,
    "learning_rate": 0.00010306666666666666,
    "epoch": 0.9733333333333334,
    "step": 730
  },
  {
    "loss": 2.4076,
    "grad_norm": 0.5427061319351196,
    "learning_rate": 0.00010173333333333334,
    "epoch": 0.9866666666666667,
    "step": 740
  },
  {
    "loss": 2.4696,
    "grad_norm": 0.520987868309021,
    "learning_rate": 0.0001004,
    "epoch": 1.0,
    "step": 750
  },
  {
    "loss": 2.3058,
    "grad_norm": 0.47513410449028015,
    "learning_rate": 9.906666666666667e-05,
    "epoch": 1.0133333333333334,
    "step": 760
  },
  {
    "loss": 2.2664,
    "grad_norm": 0.5654051899909973,
    "learning_rate": 9.773333333333334e-05,
    "epoch": 1.0266666666666666,
    "step": 770
  },
  {
    "loss": 2.2978,
    "grad_norm": 0.6350354552268982,
    "learning_rate": 9.64e-05,
    "epoch": 1.04,
    "step": 780
  },
  {
    "loss": 2.2403,
    "grad_norm": 0.5981106758117676,
    "learning_rate": 9.506666666666667e-05,
    "epoch": 1.0533333333333332,
    "step": 790
  },
  {
    "loss": 2.2121,
    "grad_norm": 0.6635868549346924,
    "learning_rate": 9.373333333333334e-05,
    "epoch": 1.0666666666666667,
    "step": 800
  },
  {
    "eval_loss": 2.277172327041626,
    "eval_runtime": 220.4412,
    "eval_samples_per_second": 2.268,
    "eval_steps_per_second": 2.268,
    "epoch": 1.0666666666666667,
    "step": 800
  },
  {
    "loss": 2.1869,
    "grad_norm": 0.6561923623085022,
    "learning_rate": 9.240000000000001e-05,
    "epoch": 1.08,
    "step": 810
  },
  {
    "loss": 2.2662,
    "grad_norm": 0.7315425872802734,
    "learning_rate": 9.106666666666667e-05,
    "epoch": 1.0933333333333333,
    "step": 820
  },
  {
    "loss": 2.2754,
    "grad_norm": 0.46784985065460205,
    "learning_rate": 8.973333333333334e-05,
    "epoch": 1.1066666666666667,
    "step": 830
  },
  {
    "loss": 2.3154,
    "grad_norm": 0.6860512495040894,
    "learning_rate": 8.840000000000001e-05,
    "epoch": 1.12,
    "step": 840
  },
  {
    "loss": 2.3255,
    "grad_norm": 0.8034871220588684,
    "learning_rate": 8.706666666666668e-05,
    "epoch": 1.1333333333333333,
    "step": 850
  },
  {
    "loss": 2.2985,
    "grad_norm": 0.7058552503585815,
    "learning_rate": 8.573333333333333e-05,
    "epoch": 1.1466666666666667,
    "step": 860
  },
  {
    "loss": 2.2759,
    "grad_norm": 0.7921948432922363,
    "learning_rate": 8.44e-05,
    "epoch": 1.16,
    "step": 870
  },
  {
    "loss": 2.2367,
    "grad_norm": 0.89333575963974,
    "learning_rate": 8.306666666666668e-05,
    "epoch": 1.1733333333333333,
    "step": 880
  },
  {
    "loss": 2.1799,
    "grad_norm": 0.6614309549331665,
    "learning_rate": 8.173333333333335e-05,
    "epoch": 1.1866666666666668,
    "step": 890
  },
  {
    "loss": 2.2465,
    "grad_norm": 0.6983931660652161,
    "learning_rate": 8.04e-05,
    "epoch": 1.2,
    "step": 900
  },
  {
    "loss": 2.3402,
    "grad_norm": 0.7702455520629883,
    "learning_rate": 7.906666666666667e-05,
    "epoch": 1.2133333333333334,
    "step": 910
  },
  {
    "loss": 2.3093,
    "grad_norm": 0.7205338478088379,
    "learning_rate": 7.773333333333333e-05,
    "epoch": 1.2266666666666666,
    "step": 920
  },
  {
    "loss": 2.2898,
    "grad_norm": 0.7783757448196411,
    "learning_rate": 7.64e-05,
    "epoch": 1.24,
    "step": 930
  },
  {
    "loss": 2.2097,
    "grad_norm": 0.8166662454605103,
    "learning_rate": 7.506666666666667e-05,
    "epoch": 1.2533333333333334,
    "step": 940
  },
  {
    "loss": 2.2181,
    "grad_norm": 0.9420061707496643,
    "learning_rate": 7.373333333333333e-05,
    "epoch": 1.2666666666666666,
    "step": 950
  },
  {
    "loss": 2.2434,
    "grad_norm": 0.7622658610343933,
    "learning_rate": 7.24e-05,
    "epoch": 1.28,
    "step": 960
  },
  {
    "loss": 2.2501,
    "grad_norm": 0.7314361929893494,
    "learning_rate": 7.106666666666667e-05,
    "epoch": 1.2933333333333334,
    "step": 970
  },
  {
    "loss": 2.2744,
    "grad_norm": 0.5406332612037659,
    "learning_rate": 6.973333333333334e-05,
    "epoch": 1.3066666666666666,
    "step": 980
  },
  {
    "loss": 2.2319,
    "grad_norm": 0.7833696007728577,
    "learning_rate": 6.840000000000001e-05,
    "epoch": 1.32,
    "step": 990
  },
  {
    "loss": 2.1721,
    "grad_norm": 0.873741090297699,
    "learning_rate": 6.706666666666667e-05,
    "epoch": 1.3333333333333333,
    "step": 1000
  },
  {
    "eval_loss": 2.17537260055542,
    "eval_runtime": 220.2395,
    "eval_samples_per_second": 2.27,
    "eval_steps_per_second": 2.27,
    "epoch": 1.3333333333333333,
    "step": 1000
  },
  {
    "loss": 2.3081,
    "grad_norm": 0.7191596627235413,
    "learning_rate": 6.573333333333334e-05,
    "epoch": 1.3466666666666667,
    "step": 1010
  },
  {
    "loss": 2.1104,
    "grad_norm": 0.6766057014465332,
    "learning_rate": 6.440000000000001e-05,
    "epoch": 1.3599999999999999,
    "step": 1020
  },
  {
    "loss": 2.2226,
    "grad_norm": 0.7042484879493713,
    "learning_rate": 6.306666666666668e-05,
    "epoch": 1.3733333333333333,
    "step": 1030
  },
  {
    "loss": 2.1082,
    "grad_norm": 0.8073127865791321,
    "learning_rate": 6.173333333333333e-05,
    "epoch": 1.3866666666666667,
    "step": 1040
  },
  {
    "loss": 2.2044,
    "grad_norm": 0.617307722568512,
    "learning_rate": 6.04e-05,
    "epoch": 1.4,
    "step": 1050
  },
  {
    "loss": 2.2394,
    "grad_norm": 0.8466306328773499,
    "learning_rate": 5.906666666666667e-05,
    "epoch": 1.4133333333333333,
    "step": 1060
  },
  {
    "loss": 2.1879,
    "grad_norm": 1.2098686695098877,
    "learning_rate": 5.773333333333334e-05,
    "epoch": 1.4266666666666667,
    "step": 1070
  },
  {
    "loss": 2.1996,
    "grad_norm": 0.88578200340271,
    "learning_rate": 5.6399999999999995e-05,
    "epoch": 1.44,
    "step": 1080
  },
  {
    "loss": 2.2602,
    "grad_norm": 0.8891875147819519,
    "learning_rate": 5.5066666666666666e-05,
    "epoch": 1.4533333333333334,
    "step": 1090
  },
  {
    "loss": 2.3033,
    "grad_norm": 0.849478006362915,
    "learning_rate": 5.3733333333333336e-05,
    "epoch": 1.4666666666666668,
    "step": 1100
  },
  {
    "loss": 2.2298,
    "grad_norm": 0.7336010336875916,
    "learning_rate": 5.2400000000000007e-05,
    "epoch": 1.48,
    "step": 1110
  },
  {
    "loss": 2.1492,
    "grad_norm": 0.7606333494186401,
    "learning_rate": 5.106666666666668e-05,
    "epoch": 1.4933333333333334,
    "step": 1120
  },
  {
    "loss": 2.1877,
    "grad_norm": 0.7384241223335266,
    "learning_rate": 4.973333333333334e-05,
    "epoch": 1.5066666666666668,
    "step": 1130
  },
  {
    "loss": 2.2081,
    "grad_norm": 0.6550379991531372,
    "learning_rate": 4.8400000000000004e-05,
    "epoch": 1.52,
    "step": 1140
  },
  {
    "loss": 2.1982,
    "grad_norm": 0.9967947602272034,
    "learning_rate": 4.706666666666667e-05,
    "epoch": 1.5333333333333332,
    "step": 1150
  },
  {
    "loss": 2.195,
    "grad_norm": 0.9634381532669067,
    "learning_rate": 4.573333333333333e-05,
    "epoch": 1.5466666666666666,
    "step": 1160
  },
  {
    "loss": 2.202,
    "grad_norm": 1.040486454963684,
    "learning_rate": 4.44e-05,
    "epoch": 1.56,
    "step": 1170
  },
  {
    "loss": 2.2147,
    "grad_norm": 0.8136330842971802,
    "learning_rate": 4.3066666666666665e-05,
    "epoch": 1.5733333333333333,
    "step": 1180
  },
  {
    "loss": 2.1926,
    "grad_norm": 1.0601627826690674,
    "learning_rate": 4.1733333333333336e-05,
    "epoch": 1.5866666666666667,
    "step": 1190
  },
  {
    "loss": 2.2184,
    "grad_norm": 0.6102443337440491,
    "learning_rate": 4.0400000000000006e-05,
    "epoch": 1.6,
    "step": 1200
  },
  {
    "eval_loss": 2.112490653991699,
    "eval_runtime": 220.5364,
    "eval_samples_per_second": 2.267,
    "eval_steps_per_second": 2.267,
    "epoch": 1.6,
    "step": 1200
  },
  {
    "loss": 2.2261,
    "grad_norm": 0.8396324515342712,
    "learning_rate": 3.906666666666667e-05,
    "epoch": 1.6133333333333333,
    "step": 1210
  },
  {
    "loss": 2.2187,
    "grad_norm": 0.8705296516418457,
    "learning_rate": 3.773333333333334e-05,
    "epoch": 1.6266666666666667,
    "step": 1220
  },
  {
    "loss": 2.205,
    "grad_norm": 0.8113614916801453,
    "learning_rate": 3.6400000000000004e-05,
    "epoch": 1.6400000000000001,
    "step": 1230
  },
  {
    "loss": 2.2587,
    "grad_norm": 0.7159594893455505,
    "learning_rate": 3.506666666666667e-05,
    "epoch": 1.6533333333333333,
    "step": 1240
  },
  {
    "loss": 2.2077,
    "grad_norm": 0.6392906308174133,
    "learning_rate": 3.373333333333333e-05,
    "epoch": 1.6666666666666665,
    "step": 1250
  },
  {
    "loss": 2.1811,
    "grad_norm": 0.49409809708595276,
    "learning_rate": 3.24e-05,
    "epoch": 1.6800000000000002,
    "step": 1260
  },
  {
    "loss": 2.1546,
    "grad_norm": 0.8263446688652039,
    "learning_rate": 3.1066666666666665e-05,
    "epoch": 1.6933333333333334,
    "step": 1270
  },
  {
    "loss": 2.2217,
    "grad_norm": 0.8920000195503235,
    "learning_rate": 2.9733333333333336e-05,
    "epoch": 1.7066666666666666,
    "step": 1280
  },
  {
    "loss": 2.2067,
    "grad_norm": 0.6376575231552124,
    "learning_rate": 2.84e-05,
    "epoch": 1.72,
    "step": 1290
  },
  {
    "loss": 2.2367,
    "grad_norm": 1.1490002870559692,
    "learning_rate": 2.706666666666667e-05,
    "epoch": 1.7333333333333334,
    "step": 1300
  },
  {
    "loss": 2.1713,
    "grad_norm": 0.9469911456108093,
    "learning_rate": 2.5733333333333337e-05,
    "epoch": 1.7466666666666666,
    "step": 1310
  },
  {
    "loss": 2.1967,
    "grad_norm": 1.302577257156372,
    "learning_rate": 2.44e-05,
    "epoch": 1.76,
    "step": 1320
  },
  {
    "loss": 2.2,
    "grad_norm": 0.6807212829589844,
    "learning_rate": 2.3066666666666667e-05,
    "epoch": 1.7733333333333334,
    "step": 1330
  },
  {
    "loss": 2.1822,
    "grad_norm": 0.8651202917098999,
    "learning_rate": 2.1733333333333334e-05,
    "epoch": 1.7866666666666666,
    "step": 1340
  },
  {
    "loss": 2.2432,
    "grad_norm": 1.1180135011672974,
    "learning_rate": 2.04e-05,
    "epoch": 1.8,
    "step": 1350
  },
  {
    "loss": 2.0898,
    "grad_norm": 0.5410729050636292,
    "learning_rate": 1.9066666666666668e-05,
    "epoch": 1.8133333333333335,
    "step": 1360
  },
  {
    "loss": 2.1271,
    "grad_norm": 0.9205028414726257,
    "learning_rate": 1.7733333333333335e-05,
    "epoch": 1.8266666666666667,
    "step": 1370
  },
  {
    "loss": 2.2624,
    "grad_norm": 0.6630014777183533,
    "learning_rate": 1.6400000000000002e-05,
    "epoch": 1.8399999999999999,
    "step": 1380
  },
  {
    "loss": 2.1914,
    "grad_norm": 0.8357565402984619,
    "learning_rate": 1.5066666666666668e-05,
    "epoch": 1.8533333333333335,
    "step": 1390
  },
  {
    "loss": 2.1822,
    "grad_norm": 0.8014505505561829,
    "learning_rate": 1.3733333333333335e-05,
    "epoch": 1.8666666666666667,
    "step": 1400
  },
  {
    "eval_loss": 2.070180654525757,
    "eval_runtime": 220.1328,
    "eval_samples_per_second": 2.271,
    "eval_steps_per_second": 2.271,
    "epoch": 1.8666666666666667,
    "step": 1400
  },
  {
    "loss": 2.1975,
    "grad_norm": 1.072999119758606,
    "learning_rate": 1.24e-05,
    "epoch": 1.88,
    "step": 1410
  },
  {
    "loss": 2.2606,
    "grad_norm": 0.9917106032371521,
    "learning_rate": 1.1066666666666667e-05,
    "epoch": 1.8933333333333333,
    "step": 1420
  },
  {
    "loss": 2.2407,
    "grad_norm": 1.0339792966842651,
    "learning_rate": 9.733333333333334e-06,
    "epoch": 1.9066666666666667,
    "step": 1430
  },
  {
    "loss": 2.1639,
    "grad_norm": 1.0692548751831055,
    "learning_rate": 8.400000000000001e-06,
    "epoch": 1.92,
    "step": 1440
  },
  {
    "loss": 2.2054,
    "grad_norm": 0.6554216742515564,
    "learning_rate": 7.066666666666667e-06,
    "epoch": 1.9333333333333333,
    "step": 1450
  },
  {
    "loss": 2.1278,
    "grad_norm": 0.8100230693817139,
    "learning_rate": 5.733333333333333e-06,
    "epoch": 1.9466666666666668,
    "step": 1460
  },
  {
    "loss": 2.2047,
    "grad_norm": 0.9424287676811218,
    "learning_rate": 4.4e-06,
    "epoch": 1.96,
    "step": 1470
  },
  {
    "loss": 2.1849,
    "grad_norm": 1.1854312419891357,
    "learning_rate": 3.066666666666667e-06,
    "epoch": 1.9733333333333334,
    "step": 1480
  },
  {
    "loss": 2.1497,
    "grad_norm": 1.1767325401306152,
    "learning_rate": 1.7333333333333334e-06,
    "epoch": 1.9866666666666668,
    "step": 1490
  },
  {
    "loss": 2.2178,
    "grad_norm": 0.7653563618659973,
    "learning_rate": 4.0000000000000003e-07,
    "epoch": 2.0,
    "step": 1500
  },
  {
    "train_runtime": 9565.9533,
    "train_samples_per_second": 0.627,
    "train_steps_per_second": 0.157,
    "total_flos": 6.762467413244314e+16,
    "train_loss": 2.3486126963297527,
    "epoch": 2.0,
    "step": 1500
  }
]